# -*- coding: utf-8 -*-
"""PENGUINS_TREE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14AXsO5hSuDCPTawlcvNFB70-5CAw8Cy8
"""

import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from tensorflow.keras.utils import to_categorical

data = pd.read_csv("penguins.csv")

data.head(3)

data.species.unique()

data.isna().sum()

data.drop(["Unnamed: 0","year"],axis=1,inplace=True)

le = LabelEncoder()
data.species = le.fit_transform(data.species)
data.island = le.fit_transform(data.island)
data.sex = le.fit_transform(data.sex)

data.dropna(inplace=True)

X = data.drop("species", axis=1)
y = data.species

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

y_train_encoded = to_categorical(y_train)
y_test_encoded = to_categorical(y_test)

poly = PolynomialFeatures(degree=2)
X_train_poly = poly.fit_transform(X_train_scaled)
X_test_poly = poly.transform(X_test_scaled)

model = Sequential([
    Dense(128, activation='relu', input_shape=(X_train_poly.shape[1],)),
    BatchNormalization(),
    Dropout(0.4),
    Dense(128, activation='relu'),
    BatchNormalization(),
    Dropout(0.4),
    Dense(64, activation='relu'),
    BatchNormalization(),
    Dropout(0.4),
    Dense(3, activation='softmax')
])

optimizer = Adam(learning_rate=0.001)
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(X_train_poly, y_train_encoded, epochs=150, batch_size=32, validation_data=(X_test_poly, y_test_encoded))

plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.show()

loss, accuracy = model.evaluate(X_test_poly, y_test_encoded)
print("Test seti doğruluk değeri:", accuracy)